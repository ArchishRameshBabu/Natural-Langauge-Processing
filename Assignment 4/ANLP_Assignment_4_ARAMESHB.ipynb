{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "242cdce7-2d43-4944-b207-3d59a07d6fc7"
    }
   },
   "source": [
    "# ANLP Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 <br/>\n",
    "### a.\tEncode the FSA in terms of matrices, including initial and final states. (This is the transition matrix!) <br/>\n",
    "\n",
    "State A\n",
    "\n",
    "|    | S0 | S1 | S2 | S3 |\n",
    "|----|----|----|----|----|\n",
    "| S0 | 0  | 0  | 0  | 0  |\n",
    "| S1 | 0  | 0  | 0  | 1  |\n",
    "| S2 | 0  | 0  | 1  | 0  |\n",
    "| S3 | 0  | 0  | 0  | 1  |\n",
    "\n",
    "\n",
    "State B\n",
    "\n",
    "|    | S0 | S1 | S2 | S3 |\n",
    "|----|----|----|----|----|\n",
    "| S0 | 0  | 1  | 0  | 0  |\n",
    "| S1 | 0  | 1  | 0  | 1  |\n",
    "| S2 | 0  | 0  | 1  | 0  |\n",
    "| S3 | 0  | 1  | 0  | 1  |\n",
    "\n",
    "\n",
    "State C\n",
    "\n",
    "|    | S0 | S1 | S2 | S3 |\n",
    "|----|----|----|----|----|\n",
    "| S0 | 0  | 0  | 1  | 0  |\n",
    "| S1 | 0  | 0  | 0  | 0  |\n",
    "| S2 | 0  | 0  | 0  | 0  |\n",
    "| S3 | 0  | 0  | 0  | 0  |\n",
    "\n",
    "\n",
    "Initial State\n",
    "\n",
    "| S0 | S1 | S2 | S3 |\n",
    "|----|----|----|----|\n",
    "| 1  | 0  | 0  | 0  |\n",
    "\n",
    "Final State\n",
    "\n",
    "| Final State| Values \n",
    "|-------------:|---|\n",
    "| S0            | 1 | \n",
    "| S1            | 1 | \n",
    "| S2            | 1 |  \n",
    "| S3            | 0 |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b.\tDescribe the language that is accepted by the FSA as a regular expression <br/>\n",
    "\n",
    "We will be using the state elimination method to obtain the regular expression: <br/>\n",
    "\n",
    "The initial state and final state are in s0, hence we need to account for NULL values <br/>\n",
    "\n",
    "Output for s2 can only be ca*<br/>\n",
    "\n",
    "    There are two possile output for s1 one via s0 emitting b, the outcomes for that scenario are 1)bb* & 2)(b*a+b)* and the other scenario is s0 emitting a and the outcome for that will already be captured by (b*a+b)*\n",
    "\n",
    "    So the Regular expression by combining them : (ca*)|(b|a+b)*\n",
    "    \n",
    "The null outcome is captured by the second term which can accept null values also \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 : Markov Chain\n",
    "\n",
    "(a) What is the probability that after 4 steps exactly 3 lines are busy? <br/>\n",
    "\n",
    "The probability that 0 lines, 1 line, 2 lines and 3 lines are busy is <br/>\n",
    "\n",
    "=$vP^4$ <br/>\n",
    "\n",
    "= [0.18991 , 0.333, 0.2732, 0.20484] <br/>\n",
    "\n",
    "So the probability that 3 lines will be busy is 0.2048 <br/> <br/>\n",
    "\n",
    "(b) What number of lines being busy has the highest probability after 4 steps? <br/>\n",
    "\n",
    "The highest probability corresponds to one line being busy with a probability of 0.33 <br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "0aa4658a-a396-434e-b836-9bb92d56e0d6"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "from nltk.util import ngrams\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from collections import Counter,defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "d964006f-65f3-4d16-b997-405275447e18"
    }
   },
   "outputs": [],
   "source": [
    "##The below codes were taken from prof. Damir Cavar's Git Repo \"Part-of-Speech_Tagging\"\n",
    "\n",
    "##Calculating the probablity for tags and words based on Brown corpus \n",
    "tokens, tags = zip(*brown.tagged_words())\n",
    "tagCounter = Counter(tags)\n",
    "tokenCounter = Counter(tokens)\n",
    "tokenTags = defaultdict(Counter)\n",
    "for token, tag in brown.tagged_words():\n",
    "    tokenTags[token][tag] +=1\n",
    "tagTags = defaultdict(Counter)\n",
    "posBigrams = list(ngrams(tags, 2))\n",
    "for tag1, tag2 in posBigrams:\n",
    "    tagTags[tag1][tag2] += 1\n",
    "offset = 0\n",
    "initialTags = Counter()\n",
    "for x in brown.sents():\n",
    "    initTag = tags[offset]\n",
    "    initialTags[initTag] += 1\n",
    "    offset += len(x)\n",
    "\n",
    "##The above code segment was taken from prof. Damir Cavar's Git Repo \"Part-of-Speech_Tagging\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(t_1 \\dots t_5\\ |\\ w_1 \\dots w_5) = P(t_1|S)\\ P(w_1|t_1)\\ P(t_2|t_1)\\ P(w_2|t_2)\\ P(t_3|t_2)\\ P(w_3|t_3)\\ P(t_4|t_3)\\ P(w_3|t_3)\\ P(t_5|t_4)\\ P(w_4|t_4)\\ P(E|t_4)\\ P(w_5|t_5)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Word \n",
    "word=['time','flies','like','an','arrow']\n",
    "total = len(tags)\n",
    "dis_token=[]\n",
    "\n",
    "##Identifying all possible tag combination\n",
    "for i in range(len(word)):\n",
    "    x=word[i]\n",
    "    a=(tokenTags[x])\n",
    "    p=list(a.keys())\n",
    "    dis_token.append(p)\n",
    "flat_list = [item for sublist in dis_token for item in sublist]\n",
    "dis_token=np.unique(flat_list,axis=0)\n",
    "list_for_bits = list(itertools.product(dis_token, repeat=5))\n",
    "list_for_bits=pd.DataFrame(list_for_bits)\n",
    "\n",
    "##Calculating the initial probablity\n",
    "p=[]\n",
    "for i in list(flat_list): \n",
    "    p.append([i,initialTags[i]/float(total)])\n",
    "    \n",
    "p=pd.DataFrame(p)\n",
    "list_for_bits.columns = ['col1', 'col2','col3', 'col4','col5']\n",
    "p.columns=['col1','Sent Start']\n",
    "\n",
    "s1 = pd.merge(list_for_bits, p, how='left', on=['col1'])\n",
    "p=[]\n",
    "for i in list(flat_list): \n",
    "    p.append([i,tokenTags[\"time\"][i]/tagCounter[i]])\n",
    " \n",
    "\n",
    "##Calculating the probablity for the first word\n",
    "p=pd.DataFrame(p)\n",
    "p.columns=['col1','p for first token']\n",
    "s2 = pd.merge(s1, p, how='left', on=['col1'])\n",
    "s2['First value']=s2['Sent Start']*s2['p for first token']\n",
    "s3=s2.loc[s2[\"First value\"]>0,]\n",
    "\n",
    "p=[]\n",
    "for i in list(flat_list):\n",
    "    for j in list(flat_list):\n",
    "        p.append([i,j,tagTags[i][j]/tagCounter[i]])\n",
    "\n",
    "p=pd.DataFrame(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating the transition probablity for different tags\n",
    "p.columns=['col1','col2','Transition 1 to 2']\n",
    "s3 = pd.merge(s3, p, how='left', on=['col1','col2'])\n",
    "\n",
    "p.columns=['col2','col3','Transition 2 to 3']\n",
    "s3 = pd.merge(s3, p, how='left', on=['col2','col3'])\n",
    "\n",
    "p.columns=['col3','col4','Transition 3 to 4']\n",
    "s3 = pd.merge(s3, p, how='left', on=['col3','col4'])\n",
    "\n",
    "p.columns=['col4','col5','Transition 4 to 5']\n",
    "s3 = pd.merge(s3, p, how='left', on=['col4','col5'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Calculating the probablity for each word \n",
    "p=[]\n",
    "for i in list(flat_list): \n",
    "    p.append([i,tokenTags[\"flies\"][i]/tagCounter[i]])\n",
    "    \n",
    "p=pd.DataFrame(p)\n",
    "p.columns=['col2','p for 2nd token']\n",
    "s3 = pd.merge(s3, p, how='left', on=['col2'])\n",
    "\n",
    "p=[]\n",
    "for i in list(flat_list): \n",
    "    p.append([i,tokenTags[\"like\"][i]/tagCounter[i]])\n",
    "    \n",
    "p=pd.DataFrame(p)\n",
    "p.columns=['col3','p for 3rd token']\n",
    "s3 = pd.merge(s3, p, how='left', on=['col3'])\n",
    "\n",
    "\n",
    "p=[]\n",
    "for i in list(flat_list): \n",
    "    p.append([i,tokenTags[\"an\"][i]/tagCounter[i]])\n",
    "    \n",
    "p=pd.DataFrame(p)\n",
    "p.columns=['col4','p for 4th token']\n",
    "s3 = pd.merge(s3, p, how='left', on=['col4'])\n",
    "\n",
    "\n",
    "p=[]\n",
    "for i in list(flat_list): \n",
    "    p.append([i,tokenTags[\"arrow\"][i]/tagCounter[i]])\n",
    "    \n",
    "p=pd.DataFrame(p)\n",
    "p.columns=['col5','p for last token']\n",
    "s3 = pd.merge(s3, p, how='left', on=['col5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Calculating the net probablity\n",
    "s3['final prob']=s3['Sent Start']*s3['p for 2nd token']*s3['p for 3rd token']*s3['p for 4th token']* s3['p for last token']*s3['Transition 4 to 5']*s3['Transition 3 to 4']*s3['Transition 2 to 3']*s3['Transition 1 to 2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s4=s3.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum probablity is coming for the combination of \"NN-HL,VBZ-HL,CS,AT and NN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          col1    col2    col3    col4    col5  Sent Start  p for first token  \\\n",
      "4594304  NN-HL  VBZ-HL      CS      AT      NN    0.000372           0.005438   \n",
      "3834328     NN     VBZ      CS      AT      NN    0.001186           0.010146   \n",
      "2421448     NN     NNS      CS      AT      NN    0.001186           0.010146   \n",
      "4602886  NN-HL  VBZ-HL      VB      AT      NN    0.000372           0.005438   \n",
      "7030969     VB     NNS      CS      AT      NN    0.000718           0.000030   \n",
      "4576643  NN-HL     VBZ      CS      AT      NN    0.000372           0.005438   \n",
      "2490104     NN     NNS      VB      AT      NN    0.001186           0.010146   \n",
      "2426320     NN     NNS      IN      AT      NN    0.001186           0.010146   \n",
      "3839200     NN     VBZ      IN      AT      NN    0.001186           0.010146   \n",
      "7099625     VB     NNS      VB      AT      NN    0.000718           0.000030   \n",
      "4400033  NN-HL     NNS      CS      AT      NN    0.000372           0.005438   \n",
      "7035841     VB     NNS      IN      AT      NN    0.000718           0.000030   \n",
      "8443849     VB     VBZ      CS      AT      NN    0.000718           0.000030   \n",
      "4408615  NN-HL     NNS      VB      AT      NN    0.000372           0.005438   \n",
      "3902984     NN     VBZ      VB      AT      NN    0.001186           0.010146   \n",
      "4400642  NN-HL     NNS      IN      AT      NN    0.000372           0.005438   \n",
      "4577252  NN-HL     VBZ      IN      AT      NN    0.000372           0.005438   \n",
      "8448721     VB     VBZ      IN      AT      NN    0.000718           0.000030   \n",
      "4585225  NN-HL     VBZ      VB      AT      NN    0.000372           0.005438   \n",
      "3844072     NN     VBZ      JJ      AT      NN    0.001186           0.010146   \n",
      "4603390  NN-HL  VBZ-HL      VB      CC      NN    0.000372           0.005438   \n",
      "4594367  NN-HL  VBZ-HL      CS      CC      NN    0.000372           0.005438   \n",
      "2431192     NN     NNS      JJ      AT      NN    0.001186           0.010146   \n",
      "8512505     VB     VBZ      VB      AT      NN    0.000718           0.000030   \n",
      "3834832     NN     VBZ      CS      CC      NN    0.001186           0.010146   \n",
      "7040713     VB     NNS      JJ      AT      NN    0.000718           0.000030   \n",
      "2494136     NN     NNS      VB      CC      NN    0.001186           0.010146   \n",
      "4577861  NN-HL     VBZ      JJ      AT      NN    0.000372           0.005438   \n",
      "2421952     NN     NNS      CS      CC      NN    0.001186           0.010146   \n",
      "7103657     VB     NNS      VB      CC      NN    0.000718           0.000030   \n",
      "...        ...     ...     ...     ...     ...         ...                ...   \n",
      "4097380  NN-HL      AT      AT   AT-HL     NIL    0.000372           0.005438   \n",
      "4097381  NN-HL      AT      AT   AT-HL      NN    0.000372           0.005438   \n",
      "4097385  NN-HL      AT      AT   AT-HL   NN-HL    0.000372           0.005438   \n",
      "4097386  NN-HL      AT      AT   AT-HL     NNS    0.000372           0.005438   \n",
      "4097387  NN-HL      AT      AT   AT-HL      VB    0.000372           0.005438   \n",
      "4097391  NN-HL      AT      AT   AT-HL   VB-HL    0.000372           0.005438   \n",
      "4097392  NN-HL      AT      AT   AT-HL     VBZ    0.000372           0.005438   \n",
      "4097393  NN-HL      AT      AT   AT-HL  VBZ-HL    0.000372           0.005438   \n",
      "4097394  NN-HL      AT      AT   AT-NC      AT    0.000372           0.005438   \n",
      "4097395  NN-HL      AT      AT   AT-NC   AT-HL    0.000372           0.005438   \n",
      "4097396  NN-HL      AT      AT   AT-NC   AT-NC    0.000372           0.005438   \n",
      "4097375  NN-HL      AT      AT   AT-HL   AT-NC    0.000372           0.005438   \n",
      "4097374  NN-HL      AT      AT   AT-HL   AT-HL    0.000372           0.005438   \n",
      "4097373  NN-HL      AT      AT   AT-HL      AT    0.000372           0.005438   \n",
      "4097358  NN-HL      AT      AT      AT      JJ    0.000372           0.005438   \n",
      "4097352  NN-HL      AT      AT      AT      AT    0.000372           0.005438   \n",
      "4097353  NN-HL      AT      AT      AT   AT-HL    0.000372           0.005438   \n",
      "4097354  NN-HL      AT      AT      AT   AT-NC    0.000372           0.005438   \n",
      "4097355  NN-HL      AT      AT      AT      CC    0.000372           0.005438   \n",
      "4097356  NN-HL      AT      AT      AT      CS    0.000372           0.005438   \n",
      "4097357  NN-HL      AT      AT      AT      IN    0.000372           0.005438   \n",
      "4097359  NN-HL      AT      AT      AT     NIL    0.000372           0.005438   \n",
      "4097372  NN-HL      AT      AT      AT  VBZ-HL    0.000372           0.005438   \n",
      "4097360  NN-HL      AT      AT      AT      NN    0.000372           0.005438   \n",
      "4097364  NN-HL      AT      AT      AT   NN-HL    0.000372           0.005438   \n",
      "4097365  NN-HL      AT      AT      AT     NNS    0.000372           0.005438   \n",
      "4097366  NN-HL      AT      AT      AT      VB    0.000372           0.005438   \n",
      "4097370  NN-HL      AT      AT      AT   VB-HL    0.000372           0.005438   \n",
      "4097371  NN-HL      AT      AT      AT     VBZ    0.000372           0.005438   \n",
      "8706865     VB  VBZ-HL  VBZ-HL  VBZ-HL  VBZ-HL    0.000718           0.000030   \n",
      "\n",
      "          First value  Transition 1 to 2  Transition 2 to 3  \\\n",
      "4594304  2.023285e-06           0.015636           0.013889   \n",
      "3834328  1.203194e-05           0.013163           0.058050   \n",
      "2421448  1.203194e-05           0.039254           0.019615   \n",
      "4602886  2.023285e-06           0.015636           0.013889   \n",
      "7030969  2.131682e-08           0.025317           0.019615   \n",
      "4576643  2.023285e-06           0.002719           0.058050   \n",
      "2490104  1.203194e-05           0.039254           0.027708   \n",
      "2426320  1.203194e-05           0.039254           0.263201   \n",
      "3839200  1.203194e-05           0.013163           0.174827   \n",
      "7099625  2.131682e-08           0.025317           0.027708   \n",
      "4400033  2.023285e-06           0.006118           0.019615   \n",
      "7035841  2.131682e-08           0.025317           0.263201   \n",
      "8443849  2.131682e-08           0.000208           0.058050   \n",
      "4408615  2.023285e-06           0.006118           0.027708   \n",
      "3902984  1.203194e-05           0.013163           0.001085   \n",
      "4400642  2.023285e-06           0.006118           0.263201   \n",
      "4577252  2.023285e-06           0.002719           0.174827   \n",
      "8448721  2.131682e-08           0.000208           0.174827   \n",
      "4585225  2.023285e-06           0.002719           0.001085   \n",
      "3844072  1.203194e-05           0.013163           0.041232   \n",
      "4603390  2.023285e-06           0.015636           0.013889   \n",
      "4594367  2.023285e-06           0.015636           0.013889   \n",
      "2431192  1.203194e-05           0.039254           0.009526   \n",
      "8512505  2.131682e-08           0.000208           0.001085   \n",
      "3834832  1.203194e-05           0.013163           0.058050   \n",
      "7040713  2.131682e-08           0.025317           0.009526   \n",
      "2494136  1.203194e-05           0.039254           0.027708   \n",
      "4577861  2.023285e-06           0.002719           0.041232   \n",
      "2421952  1.203194e-05           0.039254           0.019615   \n",
      "7103657  2.131682e-08           0.025317           0.027708   \n",
      "...               ...                ...                ...   \n",
      "4097380  2.023285e-06           0.076139           0.000010   \n",
      "4097381  2.023285e-06           0.076139           0.000010   \n",
      "4097385  2.023285e-06           0.076139           0.000010   \n",
      "4097386  2.023285e-06           0.076139           0.000010   \n",
      "4097387  2.023285e-06           0.076139           0.000010   \n",
      "4097391  2.023285e-06           0.076139           0.000010   \n",
      "4097392  2.023285e-06           0.076139           0.000010   \n",
      "4097393  2.023285e-06           0.076139           0.000010   \n",
      "4097394  2.023285e-06           0.076139           0.000010   \n",
      "4097395  2.023285e-06           0.076139           0.000010   \n",
      "4097396  2.023285e-06           0.076139           0.000010   \n",
      "4097375  2.023285e-06           0.076139           0.000010   \n",
      "4097374  2.023285e-06           0.076139           0.000010   \n",
      "4097373  2.023285e-06           0.076139           0.000010   \n",
      "4097358  2.023285e-06           0.076139           0.000010   \n",
      "4097352  2.023285e-06           0.076139           0.000010   \n",
      "4097353  2.023285e-06           0.076139           0.000010   \n",
      "4097354  2.023285e-06           0.076139           0.000010   \n",
      "4097355  2.023285e-06           0.076139           0.000010   \n",
      "4097356  2.023285e-06           0.076139           0.000010   \n",
      "4097357  2.023285e-06           0.076139           0.000010   \n",
      "4097359  2.023285e-06           0.076139           0.000010   \n",
      "4097372  2.023285e-06           0.076139           0.000010   \n",
      "4097360  2.023285e-06           0.076139           0.000010   \n",
      "4097364  2.023285e-06           0.076139           0.000010   \n",
      "4097365  2.023285e-06           0.076139           0.000010   \n",
      "4097366  2.023285e-06           0.076139           0.000010   \n",
      "4097370  2.023285e-06           0.076139           0.000010   \n",
      "4097371  2.023285e-06           0.076139           0.000010   \n",
      "8706865  2.131682e-08           0.000000           0.000000   \n",
      "\n",
      "         Transition 3 to 4  Transition 4 to 5  p for 2nd token  \\\n",
      "4594304           0.254573           0.493839         0.013889   \n",
      "3834328           0.254573           0.493839         0.000407   \n",
      "2421448           0.254573           0.493839         0.000127   \n",
      "4602886           0.179384           0.493839         0.013889   \n",
      "7030969           0.254573           0.493839         0.000127   \n",
      "4576643           0.254573           0.493839         0.000407   \n",
      "2490104           0.179384           0.493839         0.000127   \n",
      "2426320           0.358926           0.493839         0.000127   \n",
      "3839200           0.358926           0.493839         0.000407   \n",
      "7099625           0.179384           0.493839         0.000127   \n",
      "4400033           0.254573           0.493839         0.000127   \n",
      "7035841           0.358926           0.493839         0.000127   \n",
      "8443849           0.254573           0.493839         0.000407   \n",
      "4408615           0.179384           0.493839         0.000127   \n",
      "3902984           0.179384           0.493839         0.000407   \n",
      "4400642           0.358926           0.493839         0.000127   \n",
      "4577252           0.358926           0.493839         0.000407   \n",
      "8448721           0.358926           0.493839         0.000407   \n",
      "4585225           0.179384           0.493839         0.000407   \n",
      "3844072           0.003264           0.493839         0.000407   \n",
      "4603390           0.017155           0.114693         0.013889   \n",
      "4594367           0.001987           0.114693         0.013889   \n",
      "2431192           0.003264           0.493839         0.000127   \n",
      "8512505           0.179384           0.493839         0.000407   \n",
      "3834832           0.001987           0.114693         0.000407   \n",
      "7040713           0.003264           0.493839         0.000127   \n",
      "2494136           0.017155           0.114693         0.000127   \n",
      "4577861           0.003264           0.493839         0.000407   \n",
      "2421952           0.001987           0.114693         0.000127   \n",
      "7103657           0.017155           0.114693         0.000127   \n",
      "...                    ...                ...              ...   \n",
      "4097380           0.000000           0.000000         0.000000   \n",
      "4097381           0.000000           0.000000         0.000000   \n",
      "4097385           0.000000           0.496988         0.000000   \n",
      "4097386           0.000000           0.000000         0.000000   \n",
      "4097387           0.000000           0.000000         0.000000   \n",
      "4097391           0.000000           0.000000         0.000000   \n",
      "4097392           0.000000           0.000000         0.000000   \n",
      "4097393           0.000000           0.000000         0.000000   \n",
      "4097394           0.000000           0.000000         0.000000   \n",
      "4097395           0.000000           0.000000         0.000000   \n",
      "4097396           0.000000           0.000000         0.000000   \n",
      "4097375           0.000000           0.000000         0.000000   \n",
      "4097374           0.000000           0.000000         0.000000   \n",
      "4097373           0.000000           0.000000         0.000000   \n",
      "4097358           0.000010           0.198940         0.000000   \n",
      "4097352           0.000010           0.000010         0.000000   \n",
      "4097353           0.000010           0.000000         0.000000   \n",
      "4097354           0.000010           0.000000         0.000000   \n",
      "4097355           0.000010           0.000041         0.000000   \n",
      "4097356           0.000010           0.000000         0.000000   \n",
      "4097357           0.000010           0.000031         0.000000   \n",
      "4097359           0.000010           0.000010         0.000000   \n",
      "4097372           0.000010           0.000000         0.000000   \n",
      "4097360           0.000010           0.493839         0.000000   \n",
      "4097364           0.000010           0.000031         0.000000   \n",
      "4097365           0.000010           0.073653         0.000000   \n",
      "4097366           0.000010           0.000163         0.000000   \n",
      "4097370           0.000010           0.000000         0.000000   \n",
      "4097371           0.000010           0.000010         0.000000   \n",
      "8706865           0.000000           0.000000         0.013889   \n",
      "\n",
      "         p for 3rd token  p for 4th token  p for last token    final prob  \n",
      "4594304         0.043355         0.035913          0.000085  1.872718e-17  \n",
      "3834328         0.043355         0.035913          0.000085  6.153353e-18  \n",
      "2421448         0.043355         0.035913          0.000085  1.935597e-18  \n",
      "4602886         0.006233         0.035913          0.000085  1.897100e-18  \n",
      "7030969         0.043355         0.035913          0.000085  7.560955e-19  \n",
      "4576643         0.043355         0.035913          0.000085  3.987916e-19  \n",
      "2490104         0.006233         0.035913          0.000085  2.769787e-19  \n",
      "2426320         0.000257         0.035913          0.000085  2.171873e-19  \n",
      "3839200         0.000257         0.035913          0.000085  1.549703e-19  \n",
      "7099625         0.006233         0.035913          0.000085  1.081952e-19  \n",
      "4400033         0.043355         0.035913          0.000085  9.464875e-20  \n",
      "7035841         0.000257         0.035913          0.000085  8.483912e-20  \n",
      "8443849         0.043355         0.035913          0.000085  5.882194e-20  \n",
      "4408615         0.006233         0.035913          0.000085  1.354398e-20  \n",
      "3902984         0.006233         0.035913          0.000085  1.165135e-20  \n",
      "4400642         0.000257         0.035913          0.000085  1.062024e-20  \n",
      "4577252         0.000257         0.035913          0.000085  1.004344e-20  \n",
      "8448721         0.000257         0.035913          0.000085  1.481412e-21  \n",
      "4585225         0.006233         0.035913          0.000085  7.551100e-22  \n",
      "3844072         0.000547         0.035913          0.000085  7.065937e-22  \n",
      "4603390         0.006233         0.000292          0.000085  3.421673e-22  \n",
      "4594367         0.043355         0.000292          0.000085  2.756904e-22  \n",
      "2431192         0.000547         0.035913          0.000085  1.519766e-22  \n",
      "8512505         0.006233         0.035913          0.000085  1.113791e-22  \n",
      "3834832         0.043355         0.000292          0.000085  9.058604e-23  \n",
      "7040713         0.000547         0.035913          0.000085  5.936608e-23  \n",
      "2494136         0.006233         0.000292          0.000085  4.995679e-23  \n",
      "4577861         0.000547         0.035913          0.000085  4.579351e-23  \n",
      "2421952         0.043355         0.000292          0.000085  2.849472e-23  \n",
      "7103657         0.006233         0.000292          0.000085  1.951445e-23  \n",
      "...                  ...              ...               ...           ...  \n",
      "4097380         0.000000         0.030120          0.000000  0.000000e+00  \n",
      "4097381         0.000000         0.030120          0.000085  0.000000e+00  \n",
      "4097385         0.000000         0.030120          0.000000  0.000000e+00  \n",
      "4097386         0.000000         0.030120          0.000000  0.000000e+00  \n",
      "4097387         0.000000         0.030120          0.000000  0.000000e+00  \n",
      "4097391         0.000000         0.030120          0.000000  0.000000e+00  \n",
      "4097392         0.000000         0.030120          0.000000  0.000000e+00  \n",
      "4097393         0.000000         0.030120          0.000000  0.000000e+00  \n",
      "4097394         0.000000         0.028571          0.000000  0.000000e+00  \n",
      "4097395         0.000000         0.028571          0.000000  0.000000e+00  \n",
      "4097396         0.000000         0.028571          0.000000  0.000000e+00  \n",
      "4097375         0.000000         0.030120          0.000000  0.000000e+00  \n",
      "4097374         0.000000         0.030120          0.000000  0.000000e+00  \n",
      "4097373         0.000000         0.030120          0.000000  0.000000e+00  \n",
      "4097358         0.000000         0.035913          0.000000  0.000000e+00  \n",
      "4097352         0.000000         0.035913          0.000000  0.000000e+00  \n",
      "4097353         0.000000         0.035913          0.000000  0.000000e+00  \n",
      "4097354         0.000000         0.035913          0.000000  0.000000e+00  \n",
      "4097355         0.000000         0.035913          0.000000  0.000000e+00  \n",
      "4097356         0.000000         0.035913          0.000000  0.000000e+00  \n",
      "4097357         0.000000         0.035913          0.000000  0.000000e+00  \n",
      "4097359         0.000000         0.035913          0.000000  0.000000e+00  \n",
      "4097372         0.000000         0.035913          0.000000  0.000000e+00  \n",
      "4097360         0.000000         0.035913          0.000085  0.000000e+00  \n",
      "4097364         0.000000         0.035913          0.000000  0.000000e+00  \n",
      "4097365         0.000000         0.035913          0.000000  0.000000e+00  \n",
      "4097366         0.000000         0.035913          0.000000  0.000000e+00  \n",
      "4097370         0.000000         0.035913          0.000000  0.000000e+00  \n",
      "4097371         0.000000         0.035913          0.000000  0.000000e+00  \n",
      "8706865         0.000000         0.000000          0.000000  0.000000e+00  \n",
      "\n",
      "[151875 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "##Printing the final output, the first row contains the combination of POS with maximum probablity\n",
    "s_final = s4.sort_values('final prob',ascending=False)\n",
    "print(s_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum probablity is coming for the combination of \"NN-HL,VBZ-HL,CS,AT and NN\" tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/dcavar/python-tutorial-for-ipython/blob/master/notebooks/Python%20Tutorial%20PoS%20Tagging.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The research paper discusses how the Maximum Entropy Model could be used for POS tagging and how it is an improvement over other methods like Markov Models, SDT and TBL. The paper also talks about problems in the corpus data and how we can overcome them.\n",
    "\n",
    "The Maximum Entropy models uses a Bayesian approach. The algorithm splits the data into words and for each word it identifies the POS tag that maximizes the net entropy by, looking at the probability of various tags for that word, the probability of various tags occurring before the considered word and the words around it. The author doesn’t use any smoothing techniques and removes features below a particular threshold(features which occur less that 1000 times are removed). \n",
    "\n",
    "The author used the Beam Search method to identify best combination of POS tags(Beam value considered =5), this algorithm moves  left to right and identifies POS tags for each word.It considers the top N combination of POS tags based on Entropy at any point and it will take the best POS tag at the end. The author has also identified the words that are commonly mistaken by using the development set and has created special features for these words, this treatment with special features only resulted in a marginal increase in accuracy for the test set. \n",
    "\n",
    "The author considers the Maximum Entropy method over the Markov model since the Markov model considers only words previous to the current word whereas the Maximum entropy method could any useful information from the input data for tagging. Maximum entroy method doesnot require a lot of pre processing steps like the SDT algorithm, hence it is much easier to implement and maintain. Also the author considers the Maximum Entropy better that rule based algorithms like Transformation Based Learning since the latter doesn't provide probablity scores. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {
   "environment": null,
   "summary": "A Python tutorial for Part-of-Speech Tagging",
   "url": "https://anaconda.org/dcavar/python-tutorial-pos-tagging"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nbpresent": {
   "slides": {},
   "themes": {
    "default": "e2ad077c-80e1-4c08-addc-201005506eb1",
    "theme": {
     "510cdff0-402c-4eba-bd09-b848f6dfd289": {
      "backgrounds": {
       "dc7afa04-bf90-40b1-82a5-726e3cff5267": {
        "background-color": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "id": "dc7afa04-bf90-40b1-82a5-726e3cff5267"
       }
      },
      "id": "510cdff0-402c-4eba-bd09-b848f6dfd289",
      "palette": {
       "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
        "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "rgb": [
         252,
         252,
         252
        ]
       },
       "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
        "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "rgb": [
         68,
         68,
         68
        ]
       },
       "50f92c45-a630-455b-aec3-788680ec7410": {
        "id": "50f92c45-a630-455b-aec3-788680ec7410",
        "rgb": [
         197,
         226,
         245
        ]
       },
       "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
        "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "rgb": [
         43,
         126,
         184
        ]
       },
       "efa7f048-9acb-414c-8b04-a26811511a21": {
        "id": "efa7f048-9acb-414c-8b04-a26811511a21",
        "rgb": [
         25.118061674008803,
         73.60176211453744,
         107.4819383259912
        ]
       }
      },
      "rules": {
       "a": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c"
       },
       "blockquote": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3
       },
       "code": {
        "font-family": "Anonymous Pro"
       },
       "h1": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 8
       },
       "h2": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 6
       },
       "h3": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-family": "Lato",
        "font-size": 5.5
       },
       "h4": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 5
       },
       "h5": {
        "font-family": "Lato"
       },
       "h6": {
        "font-family": "Lato"
       },
       "h7": {
        "font-family": "Lato"
       },
       "li": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3.25
       },
       "pre": {
        "font-family": "Anonymous Pro",
        "font-size": 4
       }
      },
      "text-base": {
       "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
       "font-family": "Lato",
       "font-size": 4
      }
     }
    }
   }
  },
  "toc": {
   "nav_menu": {
    "height": "121px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
